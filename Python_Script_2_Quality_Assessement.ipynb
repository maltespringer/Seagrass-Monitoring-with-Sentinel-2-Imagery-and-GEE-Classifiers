{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a4b9af",
   "metadata": {},
   "source": [
    "# 2. Quality Assessement\n",
    "\n",
    "### Get the statistical data of all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89bd5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d432c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all the exportet quality files from GEE\n",
    "def process_csv_files(directory):\n",
    "    results = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".csv\") and filename.startswith(\"ConfusionMatrix\"):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                \n",
    "                # Extract classifier and date from filename\n",
    "                classifier = re.search(r'ConfusionMatrix_(.*?)_\\d{4}-\\d{2}-\\d{2}\\.csv', filename).group(1)\n",
    "                date = re.search(r'ConfusionMatrix_.*?_(\\d{4}-\\d{2}-\\d{2})\\.csv', filename).group(1)\n",
    "                \n",
    "                # Read CSV file\n",
    "                df = pd.read_csv(filepath)\n",
    "                \n",
    "                # Extract matrix from the first row (ignoring first element in each row)\n",
    "                matrix = eval(df.iloc[0]['matrix'])\n",
    "                \n",
    "                # Initialize a dictionary to store data for each element in the matrix\n",
    "                matrix_data = {}\n",
    "                for i in range(1, len(matrix)):  # Start from 1 to skip the first row\n",
    "                    for j in range(1, len(matrix[i])):  # Start from 1 to skip the first element in each row\n",
    "                        col_name = f'cm_{i}_{j}'  # Generate column name based on matrix index (0-based)\n",
    "                        matrix_data[col_name] = matrix[i][j]\n",
    "                \n",
    "                # Append classifier and date to matrix data\n",
    "                matrix_data.update({\n",
    "                    'filename': filename,\n",
    "                    'classifier': classifier,\n",
    "                    'date': date\n",
    "                })\n",
    "                \n",
    "                results.append(matrix_data)\n",
    "    \n",
    "    # Create DataFrame from results and write to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(os.path.join(directory, 'Quality_7K.csv'), index=False)\n",
    "\n",
    "# Beispielaufruf der Funktion\n",
    "directory_path = r\"path\"\n",
    "process_csv_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f79357bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv in case you start here\n",
    "df = pd.read_csv(r\"quality_path\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b458981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cm_1_1', 'cm_1_2', 'cm_1_3', 'cm_1_4', 'cm_1_5', 'cm_1_6', 'cm_1_7',\n",
       "       'cm_2_1', 'cm_2_2', 'cm_2_3', 'cm_2_4', 'cm_2_5', 'cm_2_6', 'cm_2_7',\n",
       "       'cm_3_1', 'cm_3_2', 'cm_3_3', 'cm_3_4', 'cm_3_5', 'cm_3_6', 'cm_3_7',\n",
       "       'cm_4_1', 'cm_4_2', 'cm_4_3', 'cm_4_4', 'cm_4_5', 'cm_4_6', 'cm_4_7',\n",
       "       'cm_5_1', 'cm_5_2', 'cm_5_3', 'cm_5_4', 'cm_5_5', 'cm_5_6', 'cm_5_7',\n",
       "       'cm_6_1', 'cm_6_2', 'cm_6_3', 'cm_6_4', 'cm_6_5', 'cm_6_6', 'cm_6_7',\n",
       "       'cm_7_1', 'cm_7_2', 'cm_7_3', 'cm_7_4', 'cm_7_5', 'cm_7_6', 'cm_7_7',\n",
       "       'filename', 'classifier', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87d4a675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[343   0   4   0   0   0   4]\n",
      " [  0   6   0   0   0   0   0]\n",
      " [  1   0 335   0   8   0   3]\n",
      " [  6   0   0 317   0   0   0]\n",
      " [  0   0   0   0 310   0   1]\n",
      " [ 24  11  39  13 122  49  79]\n",
      " [  5   0  14   0   0   0 306]]\n"
     ]
    }
   ],
   "source": [
    "# function to compute a confusion matrix from the raw data\n",
    "def get_confusion_matrix(row_number, results_df):\n",
    "    row = results_df.iloc[row_number]\n",
    "    \n",
    "    num_classes = 7\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    for i in range(1, num_classes + 1):\n",
    "        for j in range(1, num_classes + 1):\n",
    "            confusion_matrix[i-1, j-1] = row[f'cm_{i}_{j}']\n",
    "    \n",
    "    return confusion_matrix\n",
    "\n",
    "mat1 = get_confusion_matrix(1, df)\n",
    "\n",
    "print(mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7801a502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Overall): 0.833\n",
      "Accuracy Score (Per Class):\n",
      "Class 1: 0.9772079772079773\n",
      "Class 2: 1.0\n",
      "Class 3: 0.9654178674351584\n",
      "Class 4: 0.9814241486068112\n",
      "Class 5: 0.9967845659163987\n",
      "Class 6: 0.14540059347181009\n",
      "Class 7: 0.9415384615384615\n"
     ]
    }
   ],
   "source": [
    "# get required data\n",
    "true_positives = np.diag(mat1)\n",
    "\n",
    "actual = np.sum(mat1, axis=1)\n",
    "\n",
    "predicted = np.sum(mat1, axis=0)\n",
    "\n",
    "total = np.sum(mat1)\n",
    "\n",
    "accuracies = true_positives / actual\n",
    "\n",
    "accuracy = np.sum(true_positives) / total\n",
    "\n",
    "print(f\"Accuracy Score (Overall): {accuracy}\")\n",
    "print(\"Accuracy Score (Per Class):\")\n",
    "for i, acc in enumerate(accuracies):\n",
    "    print(f\"Class {i+1}: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b07262",
   "metadata": {},
   "source": [
    "### Prepare the quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da31bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use prewritten functions\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fad0b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(row):\n",
    "    num_classes = 7\n",
    "    \n",
    "    mat = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    for i in range(1, num_classes + 1):\n",
    "        for j in range(1, num_classes + 1):\n",
    "            mat[i-1, j-1] = row[f'cm_{i}_{j}']\n",
    "    \n",
    "    \n",
    "    true_positives = np.diag(mat)\n",
    "    total = np.sum(mat)\n",
    "    \n",
    "    acc = np.sum(true_positives) / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7bb0c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kappa(row):\n",
    "    num_classes = 7\n",
    "    \n",
    "    mat = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    for i in range(1, num_classes + 1):\n",
    "        for j in range(1, num_classes + 1):\n",
    "            mat[i-1, j-1] = row[f'cm_{i}_{j}']\n",
    "    \n",
    "    total = np.sum(mat)\n",
    "    \n",
    "    observed_agreement = np.trace(mat) / total\n",
    "    \n",
    "    row_marginals = np.sum(mat, axis=1) / total\n",
    "    column_marginals = np.sum(mat, axis=0) / total\n",
    "    expected_agreement = np.sum(row_marginals * column_marginals)\n",
    "    \n",
    "    kappa = (observed_agreement - expected_agreement) / (1 - expected_agreement)\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51e7f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(row):\n",
    "    num_classes = 7\n",
    "    \n",
    "    mat = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    for i in range(1, num_classes + 1):\n",
    "        for j in range(1, num_classes + 1):\n",
    "            mat[i-1, j-1] = row[f'cm_{i}_{j}']\n",
    "    \n",
    "    precision = np.zeros(num_classes)\n",
    "    recall = np.zeros(num_classes)\n",
    "    f1_scores = np.zeros(num_classes)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        tp = mat[i, i]\n",
    "        fp = np.sum(mat[:, i]) - tp\n",
    "        fn = np.sum(mat[i, :]) - tp\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if tp + fp > 0:\n",
    "            precision[i] = tp / (tp + fp)\n",
    "        if tp + fn > 0:\n",
    "            recall[i] = tp / (tp + fn)\n",
    "        \n",
    "        if precision[i] + recall[i] > 0:\n",
    "            f1_scores[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "    \n",
    "    # Macro F1-score\n",
    "    macro_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70f83f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['accuracy'] = df.apply(calculate_accuracy, axis=1)\n",
    "df['kappa'] = df.apply(calculate_kappa, axis=1)\n",
    "df['fscore'] = df.apply(calculate_f1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c47e69b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cm_1_1  cm_1_2  cm_1_3  cm_1_4  cm_1_5  cm_1_6  cm_1_7  cm_2_1  cm_2_2  \\\n",
      "0      442       0      17       0       8       0      52       0       0   \n",
      "1      343       0       4       0       0       0       4       0       6   \n",
      "2      483       0      18       0       0       0      18       0       0   \n",
      "3      474       0      19       0       0       0      26       0       0   \n",
      "4      471       0      23       0       0       0      25       0       0   \n",
      "5      177       0      51       0       4       0     287       0       0   \n",
      "6      453       0      27       4       4       4      19       0       5   \n",
      "7      327       0       8       0       0       0       1       0     146   \n",
      "8      472       0      28       2       0       0       9       0       6   \n",
      "9      442       0      36       4       4       0      25       0       3   \n",
      "10     461       0      35       4       0       0      11       0       6   \n",
      "11     339       2      46       2      66       0      56       0       5   \n",
      "12     436       0       8       2      12       1      27       0       4   \n",
      "13     294       0       2       0       0       0       0       0      66   \n",
      "14     476       0       5       0       0       0       5       0       4   \n",
      "15     441       0      11       3       7       0      24       0       3   \n",
      "16     466       0       6       0       0       0      14       0       4   \n",
      "17     392       0      20      10       5       0      59       0       3   \n",
      "18     442       0      20       0       4       0      41       0       2   \n",
      "19     315       0       6       0       0       0      11       0      64   \n",
      "\n",
      "    cm_2_3  ...  cm_7_4  cm_7_5  cm_7_6  cm_7_7  \\\n",
      "0        0  ...       1       5       0     363   \n",
      "1        0  ...       0       0       0     306   \n",
      "2        0  ...       0       0       0     382   \n",
      "3        0  ...       0       0       0     347   \n",
      "4        0  ...       0       0       0     370   \n",
      "5        0  ...       5       4       3     315   \n",
      "6        1  ...       4       0       0     359   \n",
      "7        0  ...       2       3       0     317   \n",
      "8        1  ...       3       0       0     389   \n",
      "9        0  ...       4       0       0     381   \n",
      "10       0  ...       2       0       0     378   \n",
      "11       2  ...       9      18       0     201   \n",
      "12       0  ...       0       0       1     404   \n",
      "13       0  ...       0       0       0     303   \n",
      "14       0  ...       0       0       0     428   \n",
      "15       0  ...       0       1       0     396   \n",
      "16       0  ...       0       0       0     414   \n",
      "17       0  ...       0      19       0     367   \n",
      "18       0  ...       0       2       0     395   \n",
      "19       0  ...       0       0       0     306   \n",
      "\n",
      "                               filename  classifier        date  accuracy  \\\n",
      "0   ConfusionMatrix_CART_2018-04-18.csv        CART  2018-04-18  0.855769   \n",
      "1   ConfusionMatrix_Cons_2018-04-18.csv        Cons  2018-04-18  0.833000   \n",
      "2    ConfusionMatrix_GBT_2018-04-18.csv         GBT  2018-04-18  0.924679   \n",
      "3    ConfusionMatrix_KNN_2018-04-18.csv         KNN  2018-04-18  0.864316   \n",
      "4     ConfusionMatrix_RF_2018-04-18.csv          RF  2018-04-18  0.910791   \n",
      "5    ConfusionMatrix_SVM_2018-04-18.csv         SVM  2018-04-18  0.699786   \n",
      "6   ConfusionMatrix_CART_2018-04-23.csv        CART  2018-04-23  0.845646   \n",
      "7   ConfusionMatrix_Cons_2018-04-23.csv        Cons  2018-04-23  0.857000   \n",
      "8    ConfusionMatrix_GBT_2018-04-23.csv         GBT  2018-04-23  0.912929   \n",
      "9    ConfusionMatrix_KNN_2018-04-23.csv         KNN  2018-04-23  0.842348   \n",
      "10    ConfusionMatrix_RF_2018-04-23.csv          RF  2018-04-23  0.893140   \n",
      "11   ConfusionMatrix_SVM_2018-04-23.csv         SVM  2018-04-23  0.608179   \n",
      "12  ConfusionMatrix_CART_2018-05-03.csv        CART  2018-05-03  0.880663   \n",
      "13  ConfusionMatrix_Cons_2018-05-03.csv        Cons  2018-05-03  0.819000   \n",
      "14   ConfusionMatrix_GBT_2018-05-03.csv         GBT  2018-05-03  0.946409   \n",
      "15   ConfusionMatrix_KNN_2018-05-03.csv         KNN  2018-05-03  0.876243   \n",
      "16    ConfusionMatrix_RF_2018-05-03.csv          RF  2018-05-03  0.932597   \n",
      "17   ConfusionMatrix_SVM_2018-05-03.csv         SVM  2018-05-03  0.705525   \n",
      "18  ConfusionMatrix_CART_2018-05-05.csv        CART  2018-05-05  0.841503   \n",
      "19  ConfusionMatrix_Cons_2018-05-05.csv        Cons  2018-05-05  0.839339   \n",
      "\n",
      "       kappa    fscore  \n",
      "0   0.809793  0.692070  \n",
      "1   0.800190  0.752974  \n",
      "2   0.900694  0.707315  \n",
      "3   0.820849  0.631196  \n",
      "4   0.882468  0.699373  \n",
      "5   0.607632  0.605473  \n",
      "6   0.791133  0.820486  \n",
      "7   0.830209  0.849843  \n",
      "8   0.882273  0.896318  \n",
      "9   0.785778  0.737831  \n",
      "10  0.855734  0.885742  \n",
      "11  0.477380  0.666541  \n",
      "12  0.842376  0.817728  \n",
      "13  0.785906  0.791370  \n",
      "14  0.929244  0.918568  \n",
      "15  0.836767  0.749109  \n",
      "16  0.911030  0.871622  \n",
      "17  0.612780  0.704736  \n",
      "18  0.791435  0.827947  \n",
      "19  0.809618  0.815108  \n",
      "\n",
      "[20 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "353af29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\MS\\OneDrive\\Studium\\Geographie\\Geo-BA\\Data\\Classification\\Quality\\Quality_7K_with_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a6d93",
   "metadata": {},
   "source": [
    "### Make table of all the statistical parameters about the quality assessement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3aeb65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data in case yout start here\n",
    "df_qa = pd.read_csv(r'C:\\Users\\MS\\OneDrive\\Studium\\Geographie\\Geo-BA\\Data\\Classification\\Quality\\Quality_7K_with_metrics.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "599ac4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = df_qa[['classifier', 'accuracy', 'kappa', 'fscore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4875d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    classifier  accuracy     kappa    fscore\n",
      "0         CART  0.855769  0.809793  0.692070\n",
      "1         Cons  0.833000  0.800190  0.752974\n",
      "2          GBT  0.924679  0.900694  0.707315\n",
      "3          KNN  0.864316  0.820849  0.631196\n",
      "4           RF  0.910791  0.882468  0.699373\n",
      "..         ...       ...       ...       ...\n",
      "487       Cons  0.901000  0.880937  0.756117\n",
      "488        GBT  0.993341  0.991209  0.813071\n",
      "489        KNN  0.960599  0.947966  0.762655\n",
      "490         RF  0.991676  0.989009  0.798170\n",
      "491        SVM  0.886238  0.849216  0.718471\n",
      "\n",
      "[492 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd45bd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               count  mean   std   min   25%   50%   75%   max\n",
      "accuracy CART   82.0  0.92  0.04  0.80  0.90  0.93  0.95  0.99\n",
      "accuracy Cons   82.0  0.83  0.04  0.71  0.81  0.83  0.85  0.92\n",
      "accuracy GBT    82.0  0.96  0.03  0.87  0.94  0.97  0.98  1.00\n",
      "accuracy KNN    82.0  0.91  0.04  0.80  0.88  0.91  0.93  0.98\n",
      "accuracy RF     82.0  0.95  0.03  0.86  0.93  0.96  0.97  1.00\n",
      "accuracy SVM    82.0  0.86  0.08  0.58  0.80  0.86  0.92  0.98\n",
      "fscore CART     82.0  0.83  0.06  0.66  0.81  0.83  0.86  0.94\n",
      "fscore Cons     82.0  0.77  0.07  0.54  0.75  0.78  0.81  0.89\n",
      "fscore GBT      82.0  0.88  0.06  0.70  0.84  0.90  0.93  0.98\n",
      "fscore KNN      82.0  0.73  0.08  0.50  0.68  0.75  0.79  0.86\n",
      "fscore RF       82.0  0.85  0.06  0.70  0.82  0.86  0.89  0.96\n",
      "fscore SVM      82.0  0.77  0.09  0.44  0.71  0.79  0.84  0.93\n",
      "kappa CART      82.0  0.90  0.05  0.74  0.87  0.91  0.94  0.99\n",
      "kappa Cons      82.0  0.80  0.04  0.65  0.77  0.80  0.82  0.91\n",
      "kappa GBT       82.0  0.95  0.04  0.84  0.92  0.96  0.97  0.99\n",
      "kappa KNN       82.0  0.88  0.05  0.74  0.84  0.89  0.92  0.97\n",
      "kappa RF        82.0  0.93  0.04  0.81  0.91  0.95  0.97  0.99\n",
      "kappa SVM       82.0  0.81  0.11  0.46  0.75  0.82  0.89  0.97\n"
     ]
    }
   ],
   "source": [
    "# make table of the data we care about\n",
    "\n",
    "pivot_df = df.pivot_table(index=df.index, columns='classifier', values=['accuracy', 'kappa', 'fscore'])\n",
    "\n",
    "pivot_df.columns = [f'{metric} {classifier}' for metric, classifier in pivot_df.columns]\n",
    "\n",
    "quality_stats = pivot_df.describe().T\n",
    "\n",
    "quality_stats = quality_stats.round(2)\n",
    "\n",
    "print(quality_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "324cbdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export table\n",
    "quality_stats.to_csv(r'C:\\Users\\MS\\OneDrive\\Studium\\Geographie\\Geo-BA\\Data\\Classification\\Quality\\Quality_7K_statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f1ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
